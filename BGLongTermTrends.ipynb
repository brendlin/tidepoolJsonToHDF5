{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args :\n",
    "    pass\n",
    "\n",
    "args.summary = True\n",
    "args.ndetailed = 4\n",
    "args.outname = 'output.root'\n",
    "args.datadir = '../BGSuggest/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from string import ascii_letters\n",
    "\n",
    "def GetInputFiles(_args) :\n",
    "    # We will process Medtronic csv files OR TidePool json files!\n",
    "    _args.match_regexp = ['Tidepool_Export.*json','Annotations_.*json']\n",
    "\n",
    "    inputfilenames = []\n",
    "    for d in os.listdir(_args.datadir) :\n",
    "        # _args.match_regexp should be a list of regexp tries\n",
    "        # (e.g. ['CareLink_Export.*csv','Tidepool_Export.*json']\n",
    "        matches = list( bool(re.match(matchstr,d)) for matchstr in _args.match_regexp)\n",
    "        if (True in matches) :\n",
    "            inputfilenames.append('%s/%s'%(_args.datadir,d))\n",
    "\n",
    "    inputfilenames = sorted(inputfilenames,key=lambda a: a.lstrip(ascii_letters+'/_.'))\n",
    "    return inputfilenames\n",
    "\n",
    "inputfiles = GetInputFiles(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start playing around with just one file\n",
    "========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_file = open(inputfiles[0])\n",
    "data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the Numpy Structured Array to work (one example)\n",
    "============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.array([(60,'2019-02-24T22:51:47'),\n",
    "                     (50,'2019-02-24T22:51:48')],dtype=[('BGReading', np.int16),('DeviceTime','datetime64[s]')])\n",
    "print(all_data)\n",
    "print(all_data.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to our case:\n",
    "============"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the data types\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Structured arrays (sequence of named fields)\n",
    "import datetime\n",
    "\n",
    "def getBGReading(i) :\n",
    "    cfactor = 1\n",
    "    if i.get('units',None) == 'mmol/L' or i.get('units',{}).get('bg',None) == 'mmol/L' :\n",
    "        cfactor = 18.01559\n",
    "    return i.get('value')*cfactor if i['type'] == 'smbg' else -1\n",
    "\n",
    "def getDeviceTime(i) :\n",
    "    try :\n",
    "        return np.datetime64(i['deviceTime'])\n",
    "    except ValueError :\n",
    "        tmp = datetime.datetime.strptime(i['deviceTime'],'%m/%d/%y %H:%M:%S').strftime('%Y-%m-%dT%H:%M:%S')\n",
    "        return np.datetime64(tmp)\n",
    "\n",
    "print('Max of int16 is:',np.iinfo(np.int16).max,'(suitable for BG)')\n",
    "\n",
    "def getDataFields() :\n",
    "    from collections import OrderedDict\n",
    "    fields = [{'name':'DeviceTime','fcn':getDeviceTime,'type':'datetime64[s]'},\n",
    "              {'name':'BGReading' ,'fcn':getBGReading ,'type':np.int16},\n",
    "             ]\n",
    "    return fields\n",
    "\n",
    "fields = getDataFields()\n",
    "dtype = list((field['name'],field['type']) for field in fields)\n",
    "print('Dtype:',dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here is something that works:\n",
    "# np.array(list(tuple(field['fcn'](i) for field in fields) for i in data[:5]),dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through files and make an np array\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate this events list with tuples containing the event info\n",
    "events = []\n",
    "\n",
    "for inputfile in inputfiles :\n",
    "\n",
    "    # print(inputfile)\n",
    "    with open(inputfile,'r') as json_file :\n",
    "        data = json.load(json_file)\n",
    "\n",
    "        for i in data :\n",
    "            if 'deviceTime' not in i.keys() :\n",
    "                continue\n",
    "            #print(i)\n",
    "\n",
    "            event = tuple()\n",
    "            for field in fields :\n",
    "                try :\n",
    "                    event += (field['fcn'](i),)\n",
    "                except KeyError :\n",
    "                    print('Exception occurred with\\n',i)\n",
    "\n",
    "            #print('One tuple:',event)\n",
    "            events.append(event)\n",
    "\n",
    "# Sort the events\n",
    "events.sort(key=lambda x: x[0])\n",
    "\n",
    "all_data = np.array(events,dtype=dtype)\n",
    "\n",
    "#print( all_data )\n",
    "#print( all_data.dtype )\n",
    "print('length of array:',len(all_data))\n",
    "\n",
    "# x = np.array(dtype=())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now start making plots!\n",
    "=========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of all BG points\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "\n",
    "\n",
    "# Trick: make a list of booleans, which can then be used to select the indices\n",
    "# corresponding to True!\n",
    "BG_indices = all_data['BGReading'] > 0\n",
    "plt.scatter(all_data['DeviceTime'][BG_indices],all_data['BGReading'][BG_indices])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rolling average of BG points in time\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_data['BGReading'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_data['DeviceTime'][0],'to',all_data['DeviceTime'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "timerange = np.arange(all_data['DeviceTime'][0]+np.timedelta64(4,'W'),\n",
    "                      all_data['DeviceTime'][-1], dtype='datetime64[D]')\n",
    "bgAverage_17wk = []\n",
    "bgRMS_17wk = []\n",
    "\n",
    "for t_plot in timerange :\n",
    "\n",
    "    bgsOfPreviousWeeks = []\n",
    "    # print(t_plot)\n",
    "    for data in all_data :\n",
    "        if data['BGReading'] < 0 :\n",
    "            continue\n",
    "        data_age = t_plot - data['DeviceTime']\n",
    "        #print ('--',data['DeviceTime'],data_age)\n",
    "        if data_age < np.timedelta64(0,'s') :\n",
    "            break\n",
    "        if data_age > np.timedelta64(17,'W') :\n",
    "            continue\n",
    "        bgsOfPreviousWeeks.append(data['BGReading'])\n",
    "\n",
    "    n = len(bgsOfPreviousWeeks)\n",
    "    if not n :\n",
    "        bgAverage_17wk.append(0)\n",
    "    mean = sum(bgsOfPreviousWeeks)/float(n)\n",
    "    bgAverage_17wk.append(mean)\n",
    "    rms = math.sqrt(sum(list(math.pow(a-mean,2) for a in bgsOfPreviousWeeks))/float(n))\n",
    "    bgRMS_17wk.append(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solid \"error bars\" are achieved using fill_between function\n",
    "avg = np.array(bgAverage_17wk)\n",
    "rms = np.array(bgRMS_17wk)\n",
    "\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "h1 = ax.plot(timerange,bgAverage_17wk,label='17-week average')\n",
    "ax.set(xlabel='time', ylabel='BG (mg/dL)',title='Seventeen-week average')\n",
    "h2 = ax.fill_between(timerange, avg-rms, avg+rms,\n",
    "                     alpha=0.5, edgecolor='#1B2ACC', facecolor='#089FFF',\n",
    "                     label='17-week average RMS')\n",
    "\n",
    "# Some reference values\n",
    "h3 = ax.plot(timerange,np.full(len(timerange),avg[-1]),label='RMS with flat BG',color='orange')\n",
    "ax.plot(timerange,avg[-1]+rms,color='orange')\n",
    "ax.plot(timerange,avg[-1]-rms,color='orange')\n",
    "\n",
    "# Manually change the order of the legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "order = [0,2,1]\n",
    "plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
